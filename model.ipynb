{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0edb0f36",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Model-Based Temporal Abstraction involves simultaneuously learning\n",
    "1) skill-conditioned low-level policy\n",
    "2) skill-conditioned temporally abstract world model\n",
    "\n",
    "Notation\n",
    "- skill-conditioned low-level policy: $\\pi_{\\theta}(a_t|s_t, z)$\n",
    "    - $\\theta$ are parameters\n",
    "    - $a_t \\in A$ is current action selected by agent\n",
    "    - $s_t \\in S$ is current state\n",
    "    - $z \\in Z$ is abstract skill variable that encodes a skill\n",
    "\n",
    "- skill-conditioned temporally abstract world model (TAWM): $p_{\\psi}(s'|s,z)$ (models distribution of states agent is in after skill $z$)\n",
    "    - $\\psi$ parameters\n",
    "    - $z$ is current skill\n",
    "\n",
    "Note: low-level policy and TAWM not trained on rewards, reward function is provided later for planning with the learned skills \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "c3e4c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages for the whole script\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal, Independent, kl_divergence\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import minari\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4bb13",
   "metadata": {},
   "source": [
    "### Learning $\\pi_{\\theta}$ and $p_{\\psi}$\n",
    "\n",
    "Learning $\\pi_{\\theta}$ and $p_{\\psi}$ requires treating skills as latent variables and optimizing the ELBO\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta,\\psi,\\phi,\\omega)\n",
    "= \\mathbb{E}_{\\tau_T \\sim \\mathcal{D}}\\!\\left[\n",
    "  \\mathbb{E}_{q_\\phi(z\\,|\\,\\tau_T)}\\!\\left[\n",
    "    \\log \\pi_\\theta(\\bar{a}\\,|\\,\\bar{s}, z)\n",
    "    + \\log p_\\psi(s_T \\,|\\, s_0, z)\n",
    "  \\right]\n",
    "  - D_{\\mathrm{KL}}\\!\\left(q_\\phi(z\\,|\\,\\tau_T)\\,\\|\\,p_\\omega(z\\,|\\,s_0)\\right)\n",
    "\\right].\n",
    "$$\n",
    "\n",
    "where $\\tau_T$ is a T-length subtrajectory sampled from the offline dataset $\\mathcal{D}$, $\\bar{s}$ and $\\bar{a}$ are state and action sequences of $\\tau_T$, $q_{\\psi}$ is a posterior over $z$ given $\\tau_T$, and $p_{\\omega}$ is a prior of $z$ given $s_0$.\n",
    "\n",
    "The first term is the log-likelihood of demonstrator actions. This ensures that the low-level policy can reproduce a demonstrator's action sequence given a skill. This forces $z$ to encode control-relevant information.\n",
    "\n",
    "The second term is the log-likelihood of long-term state transitions. This term ensures that we learn relationships between $z$ to what possible $s_T$ could result from. the skill.\n",
    "\n",
    "Finally, the last term is the KL divergence between skill posterior and prior (encourages compression of skills). Therefore, maximizing this ELBO makes skills $z$ explain the data and keeps the KL divergence small. This ensures that the skill is start-state predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695e8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to the paper, each layer contains 256 neurons\n",
    "NUM_NEURONS = 256\n",
    "# The dimension of the abstract skill variable, z\n",
    "Z_DIM = 256\n",
    "\n",
    "# Skill Posterior, q_phi\n",
    "class SkillPosterior(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: sequence of skills and actions\n",
    "    Output: mean and std over z\n",
    "\n",
    "    1. Linear layer w/ ReLU activation for the state sequence\n",
    "    2. Single-layer bidirectional GRU for embedded states and action sequence (concatenated)\n",
    "    3. Extract mean and std of layer 2's output\n",
    "    \"\"\"\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super().__init__()\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.fc1 = nn.Linear(in_features=self.state_dim, out_features=NUM_NEURONS)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bi_gru = nn.GRU(input_size=NUM_NEURONS+self.action_dim, hidden_size= NUM_NEURONS//2, bidirectional=True, batch_first=True)\n",
    "        self.mean = MeanNetwork(Z_DIM)\n",
    "        self.std = StandardDeviationNetwork(Z_DIM)\n",
    "\n",
    "    def forward(self, state_sequence, action_sequence):\n",
    "        embedded_states = self.relu(self.fc1(state_sequence))\n",
    "        concatenated = torch.cat([embedded_states, action_sequence], dim=-1)\n",
    "        x, _ = self.bi_gru(concatenated) # [B, T, NUM_NEURONS]\n",
    "        seq_emb = x.mean(dim=1) # [B, NUM_NEURONS]\n",
    "        mean = self.mean.forward(seq_emb)\n",
    "        std = self.std.forward(seq_emb)\n",
    "        return mean, std\n",
    "\n",
    "# Low-Level Skill-Conditioned Policy, pi_theta\n",
    "class SkillPolicy(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: Current state and a skill, z\n",
    "    Output: mean and std over a\n",
    "\n",
    "    1. 2-layer shared network w/ ReLU activations for the state and abstract skill (concatenated)\n",
    "    2. Extract mean and std of layer 1's output\n",
    "    \"\"\"\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.fc1 = nn.Linear(in_features=self.state_dim+Z_DIM, out_features=NUM_NEURONS)\n",
    "        self.fc2 = nn.Linear(in_features=NUM_NEURONS, out_features=NUM_NEURONS)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mean = MeanNetwork(self.action_dim)\n",
    "        self.std = StandardDeviationNetwork(self.action_dim)\n",
    "    \n",
    "    def forward(self, state, z):\n",
    "        c = torch.cat([state, z], dim=-1)\n",
    "        x = self.relu(self.fc1(c))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        mean = self.mean(x)\n",
    "        std = self.std(x)\n",
    "        return mean, std\n",
    "        \n",
    "\n",
    "# Temporally-Abstract World Model, p_psi\n",
    "class TAWM(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: initial state, along with the abstract skill\n",
    "    Output: mean and std over terminal state\n",
    "\n",
    "    1. 2-layer shared network w/ ReLU activations for initial state and abstract skill (concatenated)\n",
    "    2. Extract mean and std of layer 1's output\n",
    "    \"\"\"\n",
    "    def __init__(self, state_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.state_dim = state_dim\n",
    "        self.fc1 = nn.Linear(in_features=self.state_dim+Z_DIM, out_features=NUM_NEURONS)\n",
    "        self.fc2 = nn.Linear(in_features=NUM_NEURONS, out_features=NUM_NEURONS)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mean = MeanNetwork(self.state_dim)\n",
    "        self.std = StandardDeviationNetwork(self.state_dim)\n",
    "    \n",
    "    def forward(self, input_state, z):\n",
    "        c = torch.cat([input_state, z], dim=-1)\n",
    "        x = self.relu(self.fc1(c))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        mean = self.mean(x)\n",
    "        std = self.std(x)\n",
    "        return mean, std\n",
    "\n",
    "# Skill Prior, p_omega\n",
    "class SkillPrior(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: Initial state, s0, in the trajectory\n",
    "    Output: mean and std over the abstract skill, z\n",
    "\n",
    "    1. 2-layer shared network w/ ReLU activations for the initial state\n",
    "    2. Extract mean and std of layer 1's output\n",
    "    \"\"\"\n",
    "    def __init__(self, state_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.state_dim = state_dim\n",
    "        self.fc1 = nn.Linear(in_features=self.state_dim, out_features=NUM_NEURONS)\n",
    "        self.fc2 = nn.Linear(in_features=NUM_NEURONS, out_features=NUM_NEURONS)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mean = MeanNetwork(Z_DIM)\n",
    "        self.std = StandardDeviationNetwork(Z_DIM)\n",
    "    \n",
    "    def forward(self, input_state):\n",
    "        x = self.relu(self.fc1(input_state))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        mean = self.mean(x)\n",
    "        std = self.std(x)\n",
    "        return mean, std\n",
    "\n",
    "class MeanNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: tensor to calculate mean\n",
    "    Output: mean of input w/ dimension out_dim\n",
    "\n",
    "    1. 2-layer network w/ ReLU activation for the first layer\n",
    "    \"\"\"\n",
    "    def __init__(self, out_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=NUM_NEURONS, out_features=NUM_NEURONS)\n",
    "        self.fc2 = nn.Linear(in_features=NUM_NEURONS, out_features=out_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class StandardDeviationNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Input: tensor to calculate std\n",
    "    Output: std of input w/ dimension out_dim\n",
    "\n",
    "    Note: the standard deviation is lower and upper bounded at 0.05 and 2.0\n",
    "    - if std is 0, then log(std) -> inf\n",
    "    - if std is large, then can affect training\n",
    "\n",
    "    1. 2-layer linear network with ReLU activation after first layer and softplus after second\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, out_dim, min_std=0.05, max_std=2.0):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(NUM_NEURONS, NUM_NEURONS)\n",
    "        self.fc2 = nn.Linear(NUM_NEURONS, out_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.min_std = min_std\n",
    "        self.max_std = max_std\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        std = self.softplus(x) + self.min_std  # lower bound\n",
    "        std = torch.clamp(std, max=self.max_std)\n",
    "        return std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b4f8a0",
   "metadata": {},
   "source": [
    "#### The Expectation-Maximization (EM) Algorithm\n",
    "\n",
    "Since calculating the true posterior of $z$ given $\\tau_T$ is intractable, we infer $q_{\\psi}(z|\\tau_T)$.\n",
    "\n",
    "1. E-Step:\n",
    "- Update $\\psi$ w/gradient descent so that KL divergence between $q_\\psi$ and true posterior is minimized\n",
    "\n",
    "2. M-Step:\n",
    "- Fixing $q_{\\psi}$, update ($\\theta, \\psi, \\omega$) s.t. ELBO is maximized using gradient ascent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c61868",
   "metadata": {},
   "source": [
    "##### E-Step (Update $\\psi$)\n",
    "\n",
    "In this step, we want to minimize \n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{\\mathcal{T}_T\\sim\\mathcal{D}}\n",
    "\\Bigg[\n",
    "\\mathbb{E}_{z\\sim q_\\phi}\n",
    "\\bigg[\n",
    "\\log \\frac{q_\\phi\\!\\left(z\\mid \\bar{s},\\bar{a}\\right)}\n",
    "{\\pi_\\theta\\!\\left(\\bar{a}\\mid \\bar{s}, z\\right)\\,p_\\omega\\!\\left(z\\mid s_0\\right)}\n",
    "\\bigg]\n",
    "\\Bigg]\n",
    "$$\n",
    "\n",
    "Equivalently, we want to minimize $\\mathcal{KL}(q_{\\psi}||p)$ where $p$, the true posterior is \n",
    "\n",
    "$$\n",
    "p(z \\mid \\bar{s}, \\bar{a}) = \\frac{1}{\\eta}\\,\\pi_\\theta(\\bar{a}\\mid \\bar{s}, z)\\,p_\\omega(z\\mid s_0).\n",
    "$$\n",
    "\n",
    "\n",
    "##### M-Step (Update $\\theta$, $\\psi$, $\\omega$)\n",
    "\n",
    "In this step, we want to update $\\theta$, $\\psi$, and $\\omega$ using gradient ascent to maximize the ELBO from above.\n",
    "\n",
    "Both steps are trained using an Adam optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae831ff",
   "metadata": {},
   "source": [
    "##### Dataset 1: AntMaze Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "c4a079b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the AntMaze dataset in Minari format\n",
    "ant_maze_dataset = minari.load_dataset('D4RL/antmaze/medium-play-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "1cd992f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8)\n",
      "dict_keys(['achieved_goal', 'desired_goal', 'observation'])\n",
      "(1001, 27)\n"
     ]
    }
   ],
   "source": [
    "print(ant_maze_dataset[0].actions.shape)\n",
    "print(ant_maze_dataset[0].observations.keys())\n",
    "print(ant_maze_dataset[0].observations[\"observation\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "93eff05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B, the number of subtrajectories per batch (from paper)\n",
    "B = 100\n",
    "\n",
    "# T, the length of each subtrajectory (from paper)\n",
    "T = 9\n",
    "\n",
    "# AntMaze state and action dims (from Minari)\n",
    "state_dim = 27\n",
    "action_dim = 8\n",
    "\n",
    "# Initialize the models\n",
    "q_phi = SkillPosterior(state_dim=state_dim, action_dim=action_dim).to(device)\n",
    "pi_theta = SkillPolicy(state_dim=state_dim, action_dim=action_dim).to(device)\n",
    "p_psi = TAWM(state_dim=state_dim).to(device)\n",
    "p_omega = SkillPrior(state_dim=state_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "d3c71a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Input: LoadedMinari dataset and the length of the number of actions in each subtrajectory (T)\n",
    "    Output: Dictionary with keys \"s0, state_sequence, action_sequence, and sT\"\n",
    "\n",
    "    Finds all episodes that have at least T actions. Then, for each of those episodes, creates a sliding window to create subtrajectories w/ T actions\n",
    "    \"\"\"\n",
    "    def __init__(self, ant_maze_dataset, T):\n",
    "        self.T = T\n",
    "        self.subtrajectories = []\n",
    "\n",
    "        for ep in ant_maze_dataset.iterate_episodes():\n",
    "            s = ep.observations[\"observation\"]\n",
    "            a = ep.actions\n",
    "            l = len(s)\n",
    "            if l < T + 1:\n",
    "                continue\n",
    "            \n",
    "            # Consider skipping timesteps so that subtrajectories don't overlap that much\n",
    "            for t in range(0, l - T):\n",
    "                s0 = s[t]\n",
    "                state_sequence = s[t: t + T]\n",
    "                action_sequence = a[t: t + T]\n",
    "                sT = s[t + T]\n",
    "                self.subtrajectories.append((s0, state_sequence, action_sequence, sT))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subtrajectories)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s0, state_sequence, action_sequence, sT = self.subtrajectories[idx]\n",
    "        return {\n",
    "            \"s0\": torch.as_tensor(s0, dtype=torch.float32),\n",
    "            \"state_sequence\": torch.as_tensor(state_sequence, dtype=torch.float32),\n",
    "            \"action_sequence\": torch.as_tensor(action_sequence, dtype=torch.float32),\n",
    "            \"sT\": torch.as_tensor(sT, dtype=torch.float32)\n",
    "        }\n",
    "    \n",
    "def collate(batch):\n",
    "    # Vertically stacks each of the components of the subtrajectories such that the first dimension is the batch\n",
    "    return {\n",
    "        \"s0\": torch.stack([b[\"s0\"] for b in batch], 0),\n",
    "        \"state_sequence\": torch.stack([b[\"state_sequence\"] for b in batch], 0),\n",
    "        \"action_sequence\": torch.stack([b[\"action_sequence\"] for b in batch], 0),\n",
    "        \"sT\": torch.stack([b[\"sT\"] for b in batch], 0)\n",
    "    }\n",
    "\n",
    "# Create the dictionary of subtrajectories\n",
    "dataset = TrainingDataset(ant_maze_dataset, T)\n",
    "\n",
    "# Iterator w/ groups of subtrajectories from the dataset of size B \n",
    "loader = DataLoader(dataset, batch_size=B, shuffle=True, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcad857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_e_loss(batch):\n",
    "    s0  = batch[\"s0\"]               \n",
    "    S   = batch[\"state_sequence\"]   \n",
    "    A   = batch[\"action_sequence\"]  \n",
    "    Bsz, T, _ = S.shape\n",
    "\n",
    "    # Sampling z using the reparameterization trick where z = mu(tau) + std(tau) * epsilon\n",
    "    mu_q, std_q = q_phi(S, A) # [B, z_dim]\n",
    "    eps = torch.randn_like(mu_q)\n",
    "    z = (mu_q + std_q * eps)      \n",
    "\n",
    "    # Freeze the weights of the low-level skill-conditioned policy, pi_theta\n",
    "    with torch.no_grad():\n",
    "        z_bt = z.unsqueeze(1).expand(Bsz, T, -1) # [B, T, z_dim]\n",
    "        # Flatten time dimension since pi_theta does not the expect extra dim ([B * T, s_dim])\n",
    "        Sf = S.reshape(Bsz*T, -1)\n",
    "        Zf = z_bt.reshape(Bsz*T, -1)\n",
    "        mu_pi, std_pi = pi_theta(Sf, Zf)     \n",
    "        # Restore time dimension ([B, T, a_dim])\n",
    "        mu_pi  = mu_pi.view(Bsz, T, -1)\n",
    "        std_pi = std_pi.view(Bsz, T, -1)\n",
    "        # Build a MVN over independent actions at each timestep of each batch and sum log_probs across action_dim\n",
    "        pi_dist = Independent(Normal(mu_pi, std_pi), 1)\n",
    "        # Compute the log probability of observed actions\n",
    "        log_pi = pi_dist.log_prob(A) # ([B, T])    \n",
    "\n",
    "    # Freeze the weights of the skill prior, p_omega\n",
    "    with torch.no_grad():\n",
    "        # Find the distribution of the abstract skill given start states (mu_pr & std_pr: [B, z_dim])\n",
    "        mu_pr, std_pr = p_omega(s0)  \n",
    "        # Build a MVN over independent skills at each timestep of each batch and sum log_probs across z_dim\n",
    "        prior_dist = Independent(Normal(mu_pr, std_pr), 1)\n",
    "        # Compute the log-probability over the sampled skills using the prior\n",
    "        log_p_omega = prior_dist.log_prob(z)   \n",
    "\n",
    "    post_dist = Independent(Normal(mu_q, std_q), 1)\n",
    "    # Compute the log-probability over the sampled skills using the inferred posterior\n",
    "    log_q = post_dist.log_prob(z)              \n",
    "\n",
    "    # Calculate the E-objective\n",
    "    e_obj = (log_pi.sum(dim=1) + log_p_omega - log_q)\n",
    "    e_loss = -e_obj.mean() # minimize the negative objective\n",
    "    return e_loss\n",
    "\n",
    "\n",
    "\n",
    "def compute_m_loss(batch):\n",
    "    s0  = batch[\"s0\"]               \n",
    "    S   = batch[\"state_sequence\"]   \n",
    "    A   = batch[\"action_sequence\"] \n",
    "    sT  = batch[\"sT\"]               \n",
    "    Bsz, T, Sdim = S.shape\n",
    "\n",
    "    # Freeze the weights of the inferred posterior, only update omega, psi, and theta\n",
    "    with torch.no_grad():\n",
    "        mu_q, std_q = q_phi(S, A)        # [B, z_dim]\n",
    "        eps = torch.randn_like(mu_q)\n",
    "        # same reparameterization trick as E-loss\n",
    "        z = (mu_q + std_q * eps)  \n",
    "\n",
    "    z_bt = z.unsqueeze(1).expand(Bsz, T, -1)\n",
    "    # Flatten time dimension since pi_theta does not the expect extra dim ([B * T, s_dim])\n",
    "    Sf = S.reshape(Bsz*T, -1)\n",
    "    Zf = z_bt.reshape(Bsz*T, -1)\n",
    "    mu_pi, std_pi = pi_theta(Sf, Zf)    \n",
    "    # Restore time dimension ([B, T, a_dim])     \n",
    "    mu_pi = mu_pi.reshape(Bsz, T, -1)\n",
    "    std_pi = std_pi.reshape(Bsz, T, -1)\n",
    "    # Build a MVN over independent actions at each timestep of each batch and sum log_probs across action_dim\n",
    "    pi_dist = Independent(Normal(mu_pi, std_pi), 1)\n",
    "    log_pi = pi_dist.log_prob(A)               \n",
    "\n",
    "    # Zs: [B, T, z_dim]\n",
    "    mu_T, std_T = p_psi(s0, z)\n",
    "    # Build a MVN over independent terminal states at each timestep of each batch and sum log_probs across state_dim     \n",
    "    ppsi_dist = Independent(Normal(mu_T, std_T), 1)\n",
    "    # Compute the log-probability over the observed terminal states using the TAWM\n",
    "    log_p_psi = ppsi_dist.log_prob(sT)          \n",
    "\n",
    "    # Find the distribution of the abstract skill given start states (mu_pr & std_pr: [B, z_dim])\n",
    "    mu_pr, std_pr = p_omega(s0)                \n",
    "    # Build a MVN over independent skills at each timestep of each batch and sum log_probs across z_dim\n",
    "    prior_dist = Independent(Normal(mu_pr, std_pr), 1)\n",
    "    # Compute the log-probability over the sampled skills using the prior\n",
    "    log_p_omega = prior_dist.log_prob(z)   \n",
    "\n",
    "    # sum to find join log-likelihood of the whole sequence\n",
    "    obj = log_pi.sum(dim=1) + log_p_psi + log_p_omega   \n",
    "    m_loss = -obj.mean()\n",
    "    return m_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "6d4ad24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def skill_model_training():\n",
    "    q_phi.to(device).train()\n",
    "    pi_theta.to(device).train()\n",
    "    p_psi.to(device).train()\n",
    "    p_omega.to(device).train()\n",
    "\n",
    "    e_optimizer = optim.Adam(q_phi.parameters(), lr=5e-5)\n",
    "    m_optimizer = optim.Adam(list(pi_theta.parameters()) + list(p_psi.parameters()) + list(p_omega.parameters()), lr=5e-5)\n",
    "\n",
    "    for batch in loader:\n",
    "        for p in q_phi.parameters():\n",
    "            p.requires_grad_(True)\n",
    "        for m in (pi_theta, p_psi, p_omega):\n",
    "            for p in m.parameters():\n",
    "                p.requires_grad_(False)\n",
    "                \n",
    "        e_optimizer.zero_grad(set_to_none=True)\n",
    "        e_loss = compute_e_loss(batch)\n",
    "        e_loss.backward()\n",
    "        e_optimizer.step()\n",
    "\n",
    "        # freeze q_phi\n",
    "        for p in q_phi.parameters():\n",
    "            p.requires_grad_(False)\n",
    "        for m in (pi_theta, p_psi, p_omega):\n",
    "            for p in m.parameters():\n",
    "                p.requires_grad_(True)\n",
    "                \n",
    "        m_optimizer.zero_grad(set_to_none=True)\n",
    "        m_loss = compute_m_loss(batch)\n",
    "        m_loss.backward()\n",
    "        m_optimizer.step()\n",
    "\n",
    "        print(f\"E-Loss = {e_loss}\")\n",
    "        print(f\"M-Loss = {m_loss}\")\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d3c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def skill_model_training(\n",
    "    loader,\n",
    "    q_phi, pi_theta, p_psi, p_omega,\n",
    "    e_lr=5e-5, m_lr=5e-5,\n",
    "    epochs=50,\n",
    "    e_steps=1, m_steps=1,\n",
    "    grad_clip=1.0 # prevents runaway gradients\n",
    "):\n",
    "    # Skill model training setup\n",
    "    q_phi.to(device)\n",
    "    pi_theta.to(device)\n",
    "    p_psi.to(device)\n",
    "    p_omega.to(device)\n",
    "\n",
    "    e_optimizer = torch.optim.Adam(q_phi.parameters(), lr=e_lr)\n",
    "    m_optimizer = torch.optim.Adam(list(pi_theta.parameters()) + list(p_psi.parameters()) + list(p_omega.parameters()), lr=m_lr)\n",
    "\n",
    "    e_curve = []   \n",
    "    m_curve = []   \n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # Running e_loss, m_loss, and batches in current epoch\n",
    "        e_running, m_running, nb = 0.0, 0.0, 0\n",
    "\n",
    "        for batch in loader:\n",
    "            # Rebuilds dictionary but moves tensors to the device\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            nb += 1\n",
    "\n",
    "            # In E-step, train the posterior while freezing other parameters\n",
    "            q_phi.train()\n",
    "            pi_theta.eval()\n",
    "            p_psi.eval()\n",
    "            p_omega.eval()\n",
    "\n",
    "            for p in q_phi.parameters(): \n",
    "                p.requires_grad_(True)\n",
    "            for m in (pi_theta, p_psi, p_omega):\n",
    "                for p in m.parameters(): \n",
    "                    p.requires_grad_(False)\n",
    "\n",
    "            # For the e-step, \n",
    "            for _ in range(e_steps):\n",
    "                # Resent gradients\n",
    "                e_optimizer.zero_grad(set_to_none=True)\n",
    "                e_loss = compute_e_loss(batch)\n",
    "                e_loss.backward() \n",
    "                if grad_clip is not None:\n",
    "                    torch.nn.utils.clip_grad_norm_(q_phi.parameters(), grad_clip)\n",
    "                e_optimizer.step() # Update the parameters of the posterior\n",
    "\n",
    "            e_running += e_loss.item()\n",
    "\n",
    "            # Freeze posterior weights, update all other weights\n",
    "            q_phi.eval()\n",
    "            pi_theta.train()\n",
    "            p_psi.train()\n",
    "            p_omega.train()\n",
    "\n",
    "            for p in q_phi.parameters(): \n",
    "                p.requires_grad_(False)\n",
    "            for m in (pi_theta, p_psi, p_omega):\n",
    "                for p in m.parameters(): \n",
    "                    p.requires_grad_(True)\n",
    "\n",
    "            for _ in range(m_steps):\n",
    "                # Reset gradients\n",
    "                m_optimizer.zero_grad(set_to_none=True)\n",
    "                m_loss = compute_m_loss(batch)\n",
    "                m_loss.backward()\n",
    "                if grad_clip is not None:\n",
    "                    torch.nn.utils.clip_grad_norm_(list(pi_theta.parameters()) + list(p_psi.parameters()) + list(p_omega.parameters()), grad_clip)\n",
    "                m_optimizer.step() # Update theta, psi, and omega\n",
    "\n",
    "            m_running += m_loss.item()\n",
    "\n",
    "        # Calculate the average losses over all the batches in the epoch\n",
    "        e_epoch = e_running / max(1, nb)\n",
    "        m_epoch = m_running / max(1, nb)\n",
    "        e_curve.append(e_epoch)\n",
    "        m_curve.append(m_epoch)\n",
    "        print(f\"[Epoch {epoch:03d}/{epochs}]  E: {e_epoch:.4f}   M: {m_epoch:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(e_curve, label=\"E-loss\")\n",
    "    plt.plot(m_curve, label=\"M-loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"EM training losses\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return e_curve, m_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "7f6f2da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001/50]  E: 34.6321   M: 587.2893\n",
      "[Epoch 002/50]  E: 18.7181   M: 564.2154\n",
      "[Epoch 003/50]  E: 14.3338   M: 555.5850\n",
      "[Epoch 004/50]  E: 11.8708   M: 551.0396\n",
      "[Epoch 005/50]  E: 10.2931   M: 548.5038\n",
      "[Epoch 006/50]  E: 9.2057   M: 546.7163\n",
      "[Epoch 007/50]  E: 8.4040   M: 545.4306\n",
      "[Epoch 008/50]  E: 7.7825   M: 544.3742\n",
      "[Epoch 009/50]  E: 7.2769   M: 543.5378\n",
      "[Epoch 010/50]  E: 6.8484   M: 542.9135\n",
      "[Epoch 011/50]  E: 6.4756   M: 542.3097\n",
      "[Epoch 012/50]  E: 6.1471   M: 541.7917\n",
      "[Epoch 013/50]  E: 5.8573   M: 541.3920\n",
      "[Epoch 014/50]  E: 5.6009   M: 540.9686\n",
      "[Epoch 015/50]  E: 5.3650   M: 540.6116\n",
      "[Epoch 016/50]  E: 5.1603   M: 540.2273\n",
      "[Epoch 017/50]  E: 4.9698   M: 539.9982\n",
      "[Epoch 018/50]  E: 4.7942   M: 539.7353\n",
      "[Epoch 019/50]  E: 4.6350   M: 539.4810\n",
      "[Epoch 020/50]  E: 4.4839   M: 539.2131\n",
      "[Epoch 021/50]  E: 4.3414   M: 538.9758\n",
      "[Epoch 022/50]  E: 4.2132   M: 538.7621\n",
      "[Epoch 023/50]  E: 4.0907   M: 538.6684\n",
      "[Epoch 024/50]  E: 3.9821   M: 538.4522\n",
      "[Epoch 025/50]  E: 3.8715   M: 538.1860\n",
      "[Epoch 026/50]  E: 3.7711   M: 538.0031\n",
      "[Epoch 027/50]  E: 3.6783   M: 537.9357\n",
      "[Epoch 028/50]  E: 3.5837   M: 537.7999\n",
      "[Epoch 029/50]  E: 3.4987   M: 537.6189\n",
      "[Epoch 030/50]  E: 3.4164   M: 537.4847\n",
      "[Epoch 031/50]  E: 3.3397   M: 537.4152\n",
      "[Epoch 032/50]  E: 3.2639   M: 537.3257\n",
      "[Epoch 033/50]  E: 3.1909   M: 537.0967\n",
      "[Epoch 034/50]  E: 3.1168   M: 537.0379\n",
      "[Epoch 035/50]  E: 3.0546   M: 536.9509\n",
      "[Epoch 036/50]  E: 2.9806   M: 536.7448\n",
      "[Epoch 037/50]  E: 2.9242   M: 536.7361\n",
      "[Epoch 038/50]  E: 2.8640   M: 536.5963\n",
      "[Epoch 039/50]  E: 2.8064   M: 536.4220\n",
      "[Epoch 040/50]  E: 2.7475   M: 536.3580\n",
      "[Epoch 041/50]  E: 2.6942   M: 536.2519\n",
      "[Epoch 042/50]  E: 2.6431   M: 536.2010\n",
      "[Epoch 043/50]  E: 2.5955   M: 536.1006\n",
      "[Epoch 044/50]  E: 2.5420   M: 535.9980\n",
      "[Epoch 045/50]  E: 2.4941   M: 535.9653\n",
      "[Epoch 046/50]  E: 2.4489   M: 535.8943\n",
      "[Epoch 047/50]  E: 2.4069   M: 535.8007\n",
      "[Epoch 048/50]  E: 2.3622   M: 535.7278\n",
      "[Epoch 049/50]  E: 2.3181   M: 535.6265\n",
      "[Epoch 050/50]  E: 2.2732   M: 535.5919\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([34.632104935280736,\n",
       "  18.718106401495394,\n",
       "  14.333753334923136,\n",
       "  11.870766926953388,\n",
       "  10.293108207167636,\n",
       "  9.205655097172805,\n",
       "  8.404015556670304,\n",
       "  7.782496626444763,\n",
       "  7.276920088113947,\n",
       "  6.848445854860268,\n",
       "  6.475573981876838,\n",
       "  6.147124711596858,\n",
       "  5.8573420286726865,\n",
       "  5.60089017624212,\n",
       "  5.364965634688081,\n",
       "  5.160325909638097,\n",
       "  4.969755971805599,\n",
       "  4.794241927900622,\n",
       "  4.63496806736985,\n",
       "  4.483944812930995,\n",
       "  4.341430921915435,\n",
       "  4.213216802843184,\n",
       "  4.090713386402202,\n",
       "  3.982116294656988,\n",
       "  3.8714676368775773,\n",
       "  3.77109343508841,\n",
       "  3.6782950373452907,\n",
       "  3.5837183880398324,\n",
       "  3.4986904569604165,\n",
       "  3.4164115324983046,\n",
       "  3.3396665169672963,\n",
       "  3.2639087533875606,\n",
       "  3.1909066144234997,\n",
       "  3.1168312637662776,\n",
       "  3.0545678949550017,\n",
       "  2.9806281963873427,\n",
       "  2.924166094080324,\n",
       "  2.8640310614143023,\n",
       "  2.8064153846293616,\n",
       "  2.747507080512658,\n",
       "  2.6942042776389563,\n",
       "  2.643141311008944,\n",
       "  2.595454361687538,\n",
       "  2.542034269951515,\n",
       "  2.494077418269749,\n",
       "  2.4488521351047363,\n",
       "  2.406893505953659,\n",
       "  2.3622487908179943,\n",
       "  2.3180603845384935,\n",
       "  2.273223398078379],\n",
       " [587.2893141438884,\n",
       "  564.2153696736982,\n",
       "  555.5850391695576,\n",
       "  551.0395921830208,\n",
       "  548.5038017088367,\n",
       "  546.7162507026426,\n",
       "  545.4305996064217,\n",
       "  544.3742307539909,\n",
       "  543.5377822999031,\n",
       "  542.9135255136797,\n",
       "  542.3096940009825,\n",
       "  541.7917206487348,\n",
       "  541.3920080431046,\n",
       "  540.9685675405686,\n",
       "  540.6116439450171,\n",
       "  540.2273152197561,\n",
       "  539.9981530897079,\n",
       "  539.7353378849645,\n",
       "  539.4810384135093,\n",
       "  539.213075859316,\n",
       "  538.975759401629,\n",
       "  538.7621310572471,\n",
       "  538.6684198256462,\n",
       "  538.452220307627,\n",
       "  538.1859505130399,\n",
       "  538.0031152848275,\n",
       "  537.9356720955141,\n",
       "  537.7999041341966,\n",
       "  537.6189469737392,\n",
       "  537.4847255029986,\n",
       "  537.415249258472,\n",
       "  537.3257087584465,\n",
       "  537.0967109372539,\n",
       "  537.0379206565119,\n",
       "  536.950905369174,\n",
       "  536.744775156821,\n",
       "  536.7361411063902,\n",
       "  536.5962624580629,\n",
       "  536.421993144866,\n",
       "  536.358001155238,\n",
       "  536.2519097728114,\n",
       "  536.2009760887393,\n",
       "  536.1005806707567,\n",
       "  535.9980406299715,\n",
       "  535.9653028303577,\n",
       "  535.8943157995901,\n",
       "  535.8007195011262,\n",
       "  535.727776287448,\n",
       "  535.6264764539657,\n",
       "  535.5919063752698])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill_model_training(loader, q_phi, pi_theta, p_psi, p_omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eabf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 40\n",
    "K = 1000\n",
    "L = 3\n",
    "N_keep = 200\n",
    "N_iters = 10\n",
    "tau = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87568757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oposm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
