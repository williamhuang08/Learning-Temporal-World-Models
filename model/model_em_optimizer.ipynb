{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392855cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal, Independent, TransformedDistribution\n",
    "from torch.distributions.transforms import TanhTransform\n",
    "import gymnasium as gym\n",
    "import mujoco\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import minari\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "from skill_model import SkillPolicy, SkillPosterior, SkillPrior, TAWM\n",
    "from utils import save_checkpoint\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each layer contains 256 neurons\n",
    "NUM_NEURONS = 256\n",
    "# The dimension of the abstract skill variable, z\n",
    "Z_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee23aa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8)\n",
      "dict_keys(['achieved_goal', 'desired_goal', 'observation'])\n",
      "(1001, 27)\n",
      "(1001, 2)\n"
     ]
    }
   ],
   "source": [
    "# Loads the AntMaze dataset in Minari format\n",
    "ant_maze_dataset = minari.load_dataset('D4RL/antmaze/medium-diverse-v1')\n",
    "\n",
    "print(ant_maze_dataset[0].actions.shape)\n",
    "print(ant_maze_dataset[0].observations.keys())\n",
    "print(ant_maze_dataset[0].observations[\"observation\"].shape)\n",
    "print(ant_maze_dataset[0].observations[\"achieved_goal\"].shape)\n",
    "\n",
    "# B, the number of subtrajectories per batch (from paper)\n",
    "B = 100\n",
    "\n",
    "# T, the length of each subtrajectory (from paper)\n",
    "T = 40\n",
    "\n",
    "# AntMaze state and action dims (from Minari)\n",
    "state_dim = 29\n",
    "action_dim = 8\n",
    "\n",
    "# Initialize the models\n",
    "q_phi = SkillPosterior(state_dim=state_dim, action_dim=action_dim).to(device)\n",
    "pi_theta = SkillPolicy(state_dim=state_dim, action_dim=action_dim).to(device)\n",
    "p_psi = TAWM(state_dim=state_dim).to(device)\n",
    "p_omega = SkillPrior(state_dim=state_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89929230",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_episode_splits(minari_dataset, train=0.8, val=0.1, test=0.1, seed=0):\n",
    "    \"\"\"Return three lists of episode indices (train_ids, val_ids, test_ids).\"\"\"\n",
    "    # Materialize all episodes once so we know how many there are\n",
    "    episodes = list(minari_dataset.iterate_episodes())\n",
    "    n = len(episodes)\n",
    "    idxs = list(range(n))\n",
    "    # Shuffle the indices\n",
    "    random.Random(seed).shuffle(idxs)\n",
    "    n_train = int(round(train * n))\n",
    "    n_val = int(round(val * n))\n",
    "    train_ids = idxs[:n_train]\n",
    "    val_ids = idxs[n_train:n_train+n_val]\n",
    "    test_ids = idxs[n_train+n_val:]\n",
    "    return train_ids, val_ids, test_ids\n",
    "\n",
    "class SubtrajDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loops over minari_dataset.iterate_episodes(), but keeps only episodes whose index is in episode_ids\n",
    "    \"\"\"\n",
    "    def __init__(self, minari_dataset, T, episode_ids, stride=3):\n",
    "        self.T = T\n",
    "        self.items = []  \n",
    "\n",
    "        # Iterate all episodes but only process those whose global index is in episode_ids\n",
    "        for ep_idx, ep in enumerate(minari_dataset.iterate_episodes()):\n",
    "            if ep_idx not in set(episode_ids):\n",
    "                continue\n",
    "            obs = ep.observations[\"observation\"]          \n",
    "            ach = ep.observations[\"achieved_goal\"]        \n",
    "            act = ep.actions                               \n",
    "            Ltot = len(obs)\n",
    "            if Ltot < T + 1:\n",
    "                continue\n",
    "\n",
    "            state_ext = np.concatenate([obs, ach], axis=-1).astype(np.float32)\n",
    "            for t in range(0, Ltot - T, stride):\n",
    "                state_seq = state_ext[t:t+T]         \n",
    "                s0 = state_seq[0]             \n",
    "                action_seq = act[t:t+T].astype(np.float32)  \n",
    "                sT = state_ext[t+T]           \n",
    "                self.items.append((s0, state_seq, action_seq, sT))\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"standardize s0, state_sequence, and sT by (x - mean) / std\"\"\"\n",
    "        \n",
    "        s0, S, A, sT = self.items[i]\n",
    "        if hasattr(self, \"stats\") and self.stats is not None:\n",
    "            S_mean, S_std = self.stats\n",
    "            S  = (S  - S_mean) / S_std\n",
    "            s0 = (s0 - S_mean) / S_std\n",
    "            sT = (sT - S_mean) / S_std\n",
    "            A  = A\n",
    "        return {\n",
    "            \"s0\": torch.as_tensor(s0, dtype=torch.float32),\n",
    "            \"state_sequence\": torch.as_tensor(S, dtype=torch.float32),\n",
    "            \"action_sequence\": torch.as_tensor(A, dtype=torch.float32),\n",
    "            \"sT\": torch.as_tensor(sT, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "def collate(batch):\n",
    "    return {\n",
    "        \"s0\": torch.stack([b[\"s0\"] for b in batch], 0),\n",
    "        \"state_sequence\": torch.stack([b[\"state_sequence\"] for b in batch], 0),\n",
    "        \"action_sequence\": torch.stack([b[\"action_sequence\"] for b in batch], 0),\n",
    "        \"sT\": torch.stack([b[\"sT\"] for b in batch], 0),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6639cddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:800  val:0  test:200\n",
      "train:256800  val:0  test:64200\n"
     ]
    }
   ],
   "source": [
    "# Pick indices for train/test/split\n",
    "train_ids, val_ids, test_ids = make_episode_splits(ant_maze_dataset, train=0.8, val=0.0, test=0.2, seed=0)\n",
    "print(f\"train:{len(train_ids)}  val:{len(val_ids)}  test:{len(test_ids)}\")\n",
    "\n",
    "# Datasets from episode subsets\n",
    "train_ds = SubtrajDataset(ant_maze_dataset, T=T, episode_ids=train_ids, stride=3)\n",
    "val_ds = SubtrajDataset(ant_maze_dataset, T=T, episode_ids=val_ids,   stride=3)\n",
    "test_ds = SubtrajDataset(ant_maze_dataset, T=T, episode_ids=test_ids,  stride=3)  \n",
    "\n",
    "print(f\"train:{len(train_ds)}  val:{len(val_ds)}  test:{len(test_ds)}\")\n",
    "\n",
    "# find per-feature mean and std from all state_sequence timesteps in train_ds\n",
    "def compute_stats(ds):\n",
    "    Ss = []\n",
    "    for item in ds.items:\n",
    "        Ss.append(item[1])  # state_sequence [T,29]\n",
    "    S = np.concatenate([x.reshape(-1, x.shape[-1]) for x in Ss], axis=0)\n",
    "    S_mean, S_std = S.mean(0), S.std(0) + 1e-6\n",
    "    return (S_mean, S_std)\n",
    "\n",
    "S_mean, S_std = 0, 1\n",
    "\n",
    "# pass stats into datasets\n",
    "train_ds.stats = (S_mean, S_std)\n",
    "val_ds.stats = (S_mean, S_std)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=B, shuffle=True,  collate_fn=collate, drop_last=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=B, shuffle=False, collate_fn=collate, drop_last=False)\n",
    "\n",
    "test_ds.stats = (S_mean, S_std)\n",
    "test_loader = DataLoader(test_ds, batch_size=B, shuffle=False, collate_fn=collate, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1.0  \n",
    "\n",
    "def e_terms(batch):\n",
    "    s0, S, A = batch[\"s0\"], batch[\"state_sequence\"], batch[\"action_sequence\"]\n",
    "    B, T, _  = S.shape\n",
    "    denom = B * T\n",
    "\n",
    "    # Posterior q_phi(z|tau)\n",
    "    mu_q, std_q = q_phi(S, A) # [B, Z_DIM]\n",
    "    z = mu_q + std_q * torch.randn_like(mu_q) # [B, Z_DIM]\n",
    "\n",
    "    # Low-level policy pi_theta(a|s,z)\n",
    "    z_bt = z.unsqueeze(1).expand(B, T, -1) # [B, T, Z_DIM]\n",
    "    mu_pi, std_pi = pi_theta(\n",
    "        S.reshape(B*T, -1),\n",
    "        z_bt.reshape(B*T, -1)\n",
    "    )\n",
    "    mu_pi, std_pi = mu_pi.view(B, T, -1), std_pi.view(B, T, -1)\n",
    "\n",
    "    # Use plain Normal for skill prior\n",
    "    a_dist = Independent(Normal(mu_pi, std_pi), 1) # sum over action dims\n",
    "    post_dist = Independent(Normal(mu_q,  std_q),  1)\n",
    "    mu_pr, std_pr = p_omega(s0) # [B, Z_DIM]\n",
    "    prior_dist = Independent(Normal(mu_pr, std_pr), 1)\n",
    "\n",
    "    # log_pi summed over t & batch\n",
    "    log_pi    = a_dist.log_prob(A).sum() / denom # [B,T] \n",
    "    log_prior = prior_dist.log_prob(z).sum() / denom\n",
    "    log_post  = post_dist.log_prob(z).sum() / denom\n",
    "\n",
    "    E_loss = -log_pi - beta * log_prior + beta * log_post\n",
    "    return {\n",
    "        \"e_loss\": E_loss,\n",
    "        \"log_pi\": log_pi,\n",
    "        \"log_prior\": log_prior,\n",
    "        \"log_post\": log_post\n",
    "    }\n",
    "\n",
    "alpha = 1.0  \n",
    "beta  = 1.0\n",
    "\n",
    "def m_terms(batch):\n",
    "    s0, S, A, sT = batch[\"s0\"], batch[\"state_sequence\"], batch[\"action_sequence\"], batch[\"sT\"]\n",
    "    B, T, _  = S.shape\n",
    "    denom = B * T\n",
    "\n",
    "    # Posterior and sampled z\n",
    "    mu_q, std_q = q_phi(S, A)\n",
    "    z = mu_q + std_q * torch.randn_like(mu_q)\n",
    "\n",
    "    z_bt = z.unsqueeze(1).expand(B, T, -1)\n",
    "    mu_pi, std_pi = pi_theta(\n",
    "        S.reshape(B*T, -1),\n",
    "        z_bt.reshape(B*T, -1)\n",
    "    )\n",
    "    mu_pi, std_pi = mu_pi.view(B, T, -1), std_pi.view(B, T, -1)\n",
    "\n",
    "    a_dist = Independent(Normal(mu_pi, std_pi), 1)\n",
    "\n",
    "    # TAWM over terminal state\n",
    "    mu_T, std_T = p_psi(s0, z) # [B, state_dim]\n",
    "    sT_dist = Independent(Normal(mu_T, std_T), 1)\n",
    "\n",
    "    # Prior over z given s0\n",
    "    mu_pr, std_pr = p_omega(s0)\n",
    "    prior_dist = Independent(Normal(mu_pr, std_pr), 1)\n",
    "\n",
    "    sT_loss = -sT_dist.log_prob(sT).sum() / denom\n",
    "    a_loss = -a_dist.log_prob(A).sum() / denom\n",
    "    prior_loss = -prior_dist.log_prob(z).sum() / denom\n",
    "\n",
    "    M_loss = alpha * sT_loss + a_loss + beta * prior_loss\n",
    "    return {\n",
    "        \"m_loss\": M_loss,\n",
    "        \"sT_loss\": sT_loss,\n",
    "        \"a_loss\": a_loss,\n",
    "        \"prior_loss\": prior_loss\n",
    "    }\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch(val_loader, q_phi, pi_theta, p_psi, p_omega, device):\n",
    "    \"\"\"Compute validation E- and M-loss\"\"\"\n",
    "    q_phi.eval()\n",
    "    pi_theta.eval()\n",
    "    p_psi.eval()\n",
    "    p_omega.eval()\n",
    "    e_sum, m_sum, n = 0.0, 0.0, 0\n",
    "    for batch in val_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        terms = e_terms(batch)\n",
    "        e = terms[\"e_loss\"]\n",
    "        terms = m_terms(batch)\n",
    "        m = terms[\"m_loss\"]\n",
    "        e_sum += float(e.item())\n",
    "        m_sum += float(m.item())\n",
    "        n += 1\n",
    "    if n == 0: \n",
    "        return None, None\n",
    "    return e_sum / n, m_sum / n\n",
    "\n",
    "def skill_model_training_with_val(\n",
    "    train_loader, val_loader,\n",
    "    q_phi, pi_theta, p_psi, p_omega,\n",
    "    e_lr=5e-5, m_lr=5e-5,\n",
    "    epochs=50, e_steps=1, m_steps=1, grad_clip=1.0\n",
    "):\n",
    "    q_phi.to(device)\n",
    "    pi_theta.to(device)\n",
    "    p_psi.to(device)\n",
    "    p_omega.to(device)\n",
    "\n",
    "    e_opt = torch.optim.Adam(q_phi.parameters(), lr=e_lr)\n",
    "    m_opt = torch.optim.Adam(list(pi_theta.parameters()) + list(p_psi.parameters()) + list(p_omega.parameters()), lr=m_lr)\n",
    "\n",
    "    tr_e, tr_m, va_e, va_m = [], [], [], []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        q_phi.train()\n",
    "        pi_theta.train()\n",
    "        p_psi.train()\n",
    "        p_omega.train()\n",
    "        e_run = m_run = 0.0 # Running e_loss, m_loss, in current epoch\n",
    "\n",
    "        nb = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            # Rebuilds dictionary but moves tensors to the device\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            nb += 1\n",
    "\n",
    "            # E step: update q_phi\n",
    "            # train the posterior while freezing other parameters\n",
    "            q_phi.train()\n",
    "            pi_theta.eval()\n",
    "            p_psi.eval()\n",
    "            p_omega.eval()\n",
    "            for p in q_phi.parameters(): \n",
    "                p.requires_grad_(True)\n",
    "            for m in (pi_theta, p_psi, p_omega):\n",
    "                for p in m.parameters(): \n",
    "                    p.requires_grad_(False)\n",
    "\n",
    "            for _ in range(e_steps):\n",
    "                e_opt.zero_grad(set_to_none=True)\n",
    "                terms = e_terms(batch)\n",
    "                e_loss = terms[\"e_loss\"]\n",
    "                e_loss.backward()\n",
    "                if grad_clip is not None:\n",
    "                    torch.nn.utils.clip_grad_norm_(q_phi.parameters(), grad_clip)\n",
    "                e_opt.step()\n",
    "            e_run += float(e_loss.item())\n",
    "\n",
    "            # M step: update theta, psi, omega\n",
    "            # Freeze posterior weights, update all other weights\n",
    "\n",
    "            q_phi.eval()\n",
    "            pi_theta.train()\n",
    "            p_psi.train()\n",
    "            p_omega.train()\n",
    "            for p in q_phi.parameters(): \n",
    "                p.requires_grad_(False)\n",
    "            for m in (pi_theta, p_psi, p_omega):\n",
    "                for p in m.parameters(): \n",
    "                    p.requires_grad_(True)\n",
    "\n",
    "            for _ in range(m_steps):\n",
    "                # Reset gradients\n",
    "                m_opt.zero_grad(set_to_none=True)\n",
    "                terms = m_terms(batch)\n",
    "                m_loss = terms[\"m_loss\"]\n",
    "                m_loss.backward()\n",
    "                if grad_clip is not None:\n",
    "                    torch.nn.utils.clip_grad_norm_(list(pi_theta.parameters()) + list(p_psi.parameters()) + list(p_omega.parameters()),grad_clip)\n",
    "                m_opt.step()\n",
    "            m_run += float(m_loss.item())\n",
    "\n",
    "        # Calculate the average losses over all the batches in the epoch\n",
    "        e_epoch = e_run / max(1, nb)\n",
    "        m_epoch = m_run / max(1, nb)\n",
    "        tr_e.append(e_epoch)\n",
    "        tr_m.append(m_epoch)\n",
    "\n",
    "        # validation\n",
    "        ve, vm = eval_epoch(val_loader, q_phi, pi_theta, p_psi, p_omega, device)\n",
    "        va_e.append(ve); va_m.append(vm)\n",
    "\n",
    "        print(f\"[Epoch {epoch:03d}/{epochs}] \"\n",
    "              f\"train E:{e_epoch:.4f}  M:{m_epoch:.4f} \"\n",
    "              f\"| val E:{ve:.4f}  M:{vm:.4f}\")\n",
    "\n",
    "        wandb.log({\n",
    "            \"train/E_loss\": e_epoch,\n",
    "            \"train/M_loss\": m_epoch,\n",
    "            \"val/E_loss\": ve,\n",
    "            \"val/M_loss\": vm,\n",
    "            \"epoch\": epoch\n",
    "        }, step=epoch)\n",
    "\n",
    "    plt.figure(figsize=(7.5,4.5))\n",
    "    plt.plot(tr_e, label=\"Train E-loss\")\n",
    "    plt.plot(tr_m, label=\"Train M-loss\")\n",
    "    if all(v is not None for v in va_e):\n",
    "        plt.plot(va_e, label=\"Val E-loss\")\n",
    "    if all(v is not None for v in va_m):\n",
    "        plt.plot(va_m, label=\"Val M-loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
    "    plt.title(\"EM training: train vs. val losses\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    wandb.log({\"plots/loss_curves\": wandb.Image(fig)}, step=epoch)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return {\"train_E\": tr_e, \"train_M\": tr_m, \"val_E\": va_e, \"val_M\": va_m}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db9163f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwilliam-huang-08\u001b[0m (\u001b[33mwilliam-huang-08-yale-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/williamhuang/Documents/Yale/Research/CMUBiorobotics/OPOSM/wandb/run-20251124_190157-l54m4thk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/william-huang-08-yale-university/tawm-skill-learning/runs/l54m4thk' target=\"_blank\">antmaze-medium_em</a></strong> to <a href='https://wandb.ai/william-huang-08-yale-university/tawm-skill-learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/william-huang-08-yale-university/tawm-skill-learning' target=\"_blank\">https://wandb.ai/william-huang-08-yale-university/tawm-skill-learning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/william-huang-08-yale-university/tawm-skill-learning/runs/l54m4thk' target=\"_blank\">https://wandb.ai/william-huang-08-yale-university/tawm-skill-learning/runs/l54m4thk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "wandb.init(\n",
    "    project=\"tawm-skill-learning\",\n",
    "    name=\"antmaze-medium_em\",\n",
    "    config=dict(\n",
    "        B=B, T=T, Z_DIM=Z_DIM, NUM_NEURONS=NUM_NEURONS,\n",
    "        e_lr=5e-5, m_lr=5e-5, e_steps=1, m_steps=1,\n",
    "        dataset=\"D4RL/antmaze/medium-diverse-v1\",\n",
    "        device=device\n",
    "    )\n",
    ")\n",
    "\n",
    "wandb.watch([q_phi, pi_theta, p_psi, p_omega], log=\"gradients\", log_freq=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d585a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "curves = skill_model_training_with_val(train_loader, test_loader, q_phi, pi_theta, p_psi, p_omega, epochs=100, e_lr=5e-5, m_lr=5e-5, e_steps=1, m_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1dd00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25a88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(\"checkpoints/antmaze_diverse_em_250_1.pth\", q_phi, pi_theta, p_psi, p_omega, B, T, Z_DIM, NUM_NEURONS, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oposm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
